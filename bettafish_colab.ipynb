{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bettafish - AI Catan Player\n",
    "\n",
    "AlphaBeta search, MCTS, and AlphaZero on a fast bitboard engine.\n",
    "\n",
    "**Runtime**: Use GPU (T4) for neural net training, or high-RAM CPU for multi-core search benchmarks.\n",
    "\n",
    "Go to **Runtime > Change runtime type** and select your preferred hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "os.environ[\"PATH\"] = f\"{os.path.expanduser('~')}/.local/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo (or pull latest if already cloned)\nimport os\nif os.path.exists('bettafish'):\n    os.chdir('bettafish')\n    !git pull\nelse:\n    !git clone https://github.com/Samffprice/bettafish.git\n    os.chdir('bettafish')\n!pwd\n!git log --oneline -3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependencies (including Cython for the fast bitboard engine)\n",
    "# Uses the system Python (Colab's Python 3.11+)\n",
    "!uv pip install --system -e \".[colab]\" -e \"./catanatron[gym]\" 2>&1 | tail -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Cython extension for the fast bitboard engine\n",
    "!python robottler/bitboard/setup_cython.py build_ext --inplace\n",
    "\n",
    "# Verify it built\n",
    "import importlib\n",
    "from robottler.bitboard import _fast\n",
    "print(f\"Cython module loaded: {_fast.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check hardware\nimport torch\nimport multiprocessing\n\nNCPU = multiprocessing.cpu_count()\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\nprint(f\"CPU cores: {NCPU}\")\nprint(f\"\\nRecommended --workers: {max(1, NCPU - 1)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Benchmark (Gauntlet)\n\nRun the bitboard search player against baseline opponents.\n\n| Flag | Description |\n|------|-------------|\n| `--bb-search` | Use the fast bitboard search player |\n| `--search-depth N` | Search depth (2 = fast, 3 = strong) |\n| `--blend-weight W` | Neural/heuristic blend (1e8 optimal) |\n| `--dice-sample N` | Sample top-N dice rolls (5 = 3x speedup) |\n| `--games N` | Games per opponent |\n| `--workers N` | Parallel processes (use all cores!) |\n| `--baselines` | Run against all baseline opponents |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import multiprocessing; W = max(1, multiprocessing.cpu_count() - 1)\n\n# Quick benchmark: bitboard search depth 2 vs all baselines (50 games each)\n!python -m robottler.benchmark \\\n    --bb-search \\\n    --search-depth 2 \\\n    --blend-weight 1e8 \\\n    --dice-sample 5 \\\n    --baselines \\\n    --games 50 \\\n    --workers {W}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Strong benchmark: depth 3 (slower but ~72% vs AlphaBeta)\n!python -m robottler.benchmark \\\n    --bb-search \\\n    --search-depth 3 \\\n    --blend-weight 1e8 \\\n    --dice-sample 5 \\\n    --baselines \\\n    --games 20 \\\n    --workers {W}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Train on Local Data (GPU)\n\nUpload your training data from your local machine and train on Colab's GPU.\nTraining is fast on T4 (~10-15 min per experiment). Benchmarking is slow on\nColab â€” do that locally on your Mac instead.\n\n**Step 1 (local machine):** Zip your data and checkpoint:\n```bash\ncd /Volumes/BackupFiles/MasterCoding/Random-Projects/AICatan\nzip -r training_data.zip datasets/az_v2_325k_200ep.pt datasets/az_selfplay_v2 datasets/exit_v1/iter1 datasets/exit_v1/iter2 datasets/exit_v1/iter3 datasets/exit_v1/iter4 datasets/exit_v1/iter5 datasets/expert_data_10k datasets/expert_depth3 datasets/expert_ranking\n```\n\n**Step 2:** Upload `training_data.zip` to your Google Drive root folder.\n\n**Step 3:** Run the cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive and unzip training data\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os, shutil\n\nZIP_PATH = '/content/drive/MyDrive/training_data.zip'\nif os.path.exists(ZIP_PATH):\n    !unzip -qo {ZIP_PATH} -d /content/bettafish/\n    print(\"Data extracted!\")\n    # Show what we got\n    !du -sh /content/bettafish/datasets/*/\nelse:\n    print(f\"ERROR: {ZIP_PATH} not found. Upload training_data.zip to your Google Drive root.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exp #24a: Ranking loss, margin=0.1 (conservative)\n\nDATA_DIRS = \" \".join([\n    \"datasets/az_selfplay_v2\",\n    \"datasets/exit_v1/iter1\", \"datasets/exit_v1/iter2\", \"datasets/exit_v1/iter3\",\n    \"datasets/exit_v1/iter4\", \"datasets/exit_v1/iter5\",\n    \"datasets/expert_data_10k\", \"datasets/expert_depth3\",\n])\n\n!python -m robottler.az_selfplay train \\\n    --checkpoint datasets/az_v2_325k_200ep.pt \\\n    --data-dir {DATA_DIRS} \\\n    --output datasets/az_ranking_m01.pt \\\n    --epochs 200 --batch-size 16384 --lr 1e-3 \\\n    --scheduler cosine \\\n    --body-dims 512,256 --dropout 0.1 \\\n    --ranking-data datasets/expert_ranking \\\n    --ranking-weight 1.0 --ranking-margin 0.1"
  },
  {
   "cell_type": "code",
   "source": "# Exp #24b: Ranking loss, margin=0.3 (moderate)\n\n!python -m robottler.az_selfplay train \\\n    --checkpoint datasets/az_v2_325k_200ep.pt \\\n    --data-dir {DATA_DIRS} \\\n    --output datasets/az_ranking_m03.pt \\\n    --epochs 200 --batch-size 16384 --lr 1e-3 \\\n    --scheduler cosine \\\n    --body-dims 512,256 --dropout 0.1 \\\n    --ranking-data datasets/expert_ranking \\\n    --ranking-weight 1.0 --ranking-margin 0.3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Exp #24c: Ranking loss, margin=0.5 (aggressive)\n\n!python -m robottler.az_selfplay train \\\n    --checkpoint datasets/az_v2_325k_200ep.pt \\\n    --data-dir {DATA_DIRS} \\\n    --output datasets/az_ranking_m05.pt \\\n    --epochs 200 --batch-size 16384 --lr 1e-3 \\\n    --scheduler cosine \\\n    --body-dims 512,256 --dropout 0.1 \\\n    --ranking-data datasets/expert_ranking \\\n    --ranking-weight 1.0 --ranking-margin 0.5",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy trained models back to Google Drive for download\nimport shutil, os\n\nmodels = [\n    'datasets/az_ranking_m01.pt',\n    'datasets/az_ranking_m03.pt',\n    'datasets/az_ranking_m05.pt',\n]\n\nfor src in models:\n    name = os.path.basename(src)\n    dst = f'/content/drive/MyDrive/{name}'\n    if os.path.exists(src):\n        shutil.copy2(src, dst)\n        size_mb = os.path.getsize(src) / 1e6\n        print(f\"Saved {dst} ({size_mb:.1f} MB)\")\n    else:\n        print(f\"MISSING: {src}\")\n\nprint(\"\\nDownload from Google Drive, place in local datasets/ folder, then benchmark:\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_ranking_m01.pt 100 6 400\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_ranking_m03.pt 100 6 400\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_ranking_m05.pt 100 6 400\")\nprint(\"\\nMeasure Kendall tau improvement:\")\nprint(\"  python /tmp/mcts_deep_diagnostics.py datasets/az_ranking_m03.pt 5\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 3b. GNN Training (Exp #25)\n\nTrain a Graph Neural Network that processes per-node features on the board graph.\nThe GNN sees spatial layout (which nodes have buildings, adjacency) that the MLP cannot.\n\n**Step 1 (local machine):** Extract GNN features from the 44K human games:\n```bash\ncd /Volumes/BackupFiles/MasterCoding/Random-Projects/AICatan\npython3 -m datasets.extract_gnn_features \\\n    --games-dir datasets/games \\\n    --output-dir datasets/human_gnn_44k \\\n    --workers 0\n```\n\n**Step 2:** Zip and upload:\n```bash\nzip -r human_gnn_44k.zip datasets/human_gnn_44k/node_features.npy \\\n    datasets/human_gnn_44k/global_features.npy \\\n    datasets/human_gnn_44k/values.npy\n```\n\n**Step 3:** Upload `human_gnn_44k.zip` to Google Drive root, then run cells below.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Unzip GNN training data from Google Drive\nimport os\nGNN_ZIP = '/content/drive/MyDrive/human_gnn_44k.zip'\nif os.path.exists(GNN_ZIP):\n    !unzip -qo {GNN_ZIP} -d /content/bettafish/\n    print(\"GNN data extracted!\")\n    !du -sh /content/bettafish/datasets/human_gnn_44k/\n    !ls -lh /content/bettafish/datasets/human_gnn_44k/*.npy\nelse:\n    print(f\"ERROR: {GNN_ZIP} not found. Upload human_gnn_44k.zip to Google Drive.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Exp #25a: Small GNN (32,64,96) ~45K params on human game data\n!python -m robottler.az_selfplay train \\\n    --data-dir datasets/human_gnn_44k \\\n    --output datasets/gnn_human_small.pt \\\n    --gnn --gnn-dims 32,64,96 \\\n    --epochs 200 --batch-size 2048 --lr 1e-3 \\\n    --scheduler cosine --dropout 0.2 --edge-dropout 0.1",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. AlphaZero Self-Play + Training Loop\n\nAutomated generate -> train -> evaluate cycle. Use this for running full\nself-play iterations on Colab hardware."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Full loop: 5 iterations of generate/train/evaluate\n!python -m robottler.az_selfplay loop \\\n    --start-checkpoint robottler/models/az_iter0.pt \\\n    --iterations 5 \\\n    --games-per-iter 200 \\\n    --sims 200 \\\n    --output-dir datasets/az_selfplay/colab_loop \\\n    --epochs 20 \\\n    --eval-games 100 \\\n    --workers {W}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. RL Training (MaskablePPO)\n\nTrain a policy network with reinforcement learning. Benefits from **multi-core** for\nparallel environment rollouts."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m robottler.train_rl \\\n",
    "    --opponent alphabeta \\\n",
    "    --total-steps 200000 \\\n",
    "    --n-envs 8 \\\n",
    "    --bc-model robottler/models/value_net_v2.pt \\\n",
    "    --vps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Save Results\n\nDownload trained models back to your local machine."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all model checkpoints\n",
    "!ls -lh robottler/models/*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip models for download\n",
    "!zip -j colab_models.zip robottler/models/az_colab_*.pt robottler/models/az_iter*.pt 2>/dev/null || echo \"No new models yet\"\n",
    "\n",
    "from google.colab import files\n",
    "try:\n",
    "    files.download(\"colab_models.zip\")\n",
    "except:\n",
    "    print(\"Download manually from the file browser (left panel)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}