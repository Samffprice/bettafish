{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bettafish - AI Catan Player\n",
    "\n",
    "AlphaBeta search, MCTS, and AlphaZero on a fast bitboard engine.\n",
    "\n",
    "**Runtime**: Use GPU (T4) for neural net training, or high-RAM CPU for multi-core search benchmarks.\n",
    "\n",
    "Go to **Runtime > Change runtime type** and select your preferred hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "os.environ[\"PATH\"] = f\"{os.path.expanduser('~')}/.local/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo (or pull latest if already cloned)\nimport os\nif os.path.exists('bettafish'):\n    os.chdir('bettafish')\n    !git pull\nelse:\n    !git clone https://github.com/Samffprice/bettafish.git\n    os.chdir('bettafish')\n!pwd\n!git log --oneline -3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependencies (including Cython for the fast bitboard engine)\n",
    "# Uses the system Python (Colab's Python 3.11+)\n",
    "!uv pip install --system -e \".[colab]\" -e \"./catanatron[gym]\" 2>&1 | tail -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Cython extension for the fast bitboard engine\n",
    "!python robottler/bitboard/setup_cython.py build_ext --inplace\n",
    "\n",
    "# Verify it built\n",
    "import importlib\n",
    "from robottler.bitboard import _fast\n",
    "print(f\"Cython module loaded: {_fast.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check hardware\nimport torch\nimport multiprocessing\n\nNCPU = multiprocessing.cpu_count()\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\nprint(f\"CPU cores: {NCPU}\")\nprint(f\"\\nRecommended --workers: {max(1, NCPU - 1)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Benchmark (Gauntlet)\n\nRun the bitboard search player against baseline opponents.\n\n| Flag | Description |\n|------|-------------|\n| `--bb-search` | Use the fast bitboard search player |\n| `--search-depth N` | Search depth (2 = fast, 3 = strong) |\n| `--blend-weight W` | Neural/heuristic blend (1e8 optimal) |\n| `--dice-sample N` | Sample top-N dice rolls (5 = 3x speedup) |\n| `--games N` | Games per opponent |\n| `--workers N` | Parallel processes (use all cores!) |\n| `--baselines` | Run against all baseline opponents |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import multiprocessing; W = max(1, multiprocessing.cpu_count() - 1)\n\n# Quick benchmark: bitboard search depth 2 vs all baselines (50 games each)\n!python -m robottler.benchmark \\\n    --bb-search \\\n    --search-depth 2 \\\n    --blend-weight 1e8 \\\n    --dice-sample 5 \\\n    --baselines \\\n    --games 50 \\\n    --workers {W}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Strong benchmark: depth 3 (slower but ~72% vs AlphaBeta)\n!python -m robottler.benchmark \\\n    --bb-search \\\n    --search-depth 3 \\\n    --blend-weight 1e8 \\\n    --dice-sample 5 \\\n    --baselines \\\n    --games 20 \\\n    --workers {W}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Train on Local Data (GPU)\n\nUpload your training data from your local machine and train on Colab's GPU.\nTraining is fast on T4 (~10-15 min per experiment). Benchmarking is slow on\nColab â€” do that locally on your Mac instead.\n\n**Step 1 (local machine):** Zip your data and checkpoint:\n```bash\ncd /Volumes/BackupFiles/MasterCoding/Random-Projects/AICatan\nzip -r training_data.zip datasets/az_v2_325k_200ep.pt datasets/az_selfplay_v2 datasets/exit_v1/iter1 datasets/exit_v1/iter2 datasets/exit_v1/iter3 datasets/exit_v1/iter4 datasets/exit_v1/iter5 datasets/expert_data_10k datasets/expert_depth3\n```\n\n**Step 2:** Upload `training_data.zip` to your Google Drive root folder.\n\n**Step 3:** Run the cells below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive and unzip training data\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os, shutil\n\nZIP_PATH = '/content/drive/MyDrive/training_data.zip'\nif os.path.exists(ZIP_PATH):\n    !unzip -qo {ZIP_PATH} -d /content/bettafish/\n    print(\"Data extracted!\")\n    # Show what we got\n    !du -sh /content/bettafish/datasets/*/\nelse:\n    print(f\"ERROR: {ZIP_PATH} not found. Upload training_data.zip to your Google Drive root.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Exp #23: Fix value head overoptimism with asymmetric loss + negative oversampling\n# Trains 3 variants to isolate contributions. All use fresh 512,256 body,\n# 200ep cosine, same 2.07M expert data as exp #14.\n# ~10-15 min each on T4, ~30-45 min total.\n\nimport subprocess, sys\n\nDATA_DIRS = [\n    \"datasets/az_selfplay_v2\",\n    \"datasets/exit_v1/iter1\", \"datasets/exit_v1/iter2\", \"datasets/exit_v1/iter3\",\n    \"datasets/exit_v1/iter4\", \"datasets/exit_v1/iter5\",\n    \"datasets/expert_data_10k\", \"datasets/expert_depth3\",\n]\n\nCOMMON = [\n    \"python\", \"-m\", \"robottler.az_selfplay\", \"train\",\n    \"--checkpoint\", \"datasets/az_v2_325k_200ep.pt\",\n    \"--data-dir\", *DATA_DIRS,\n    \"--epochs\", \"200\", \"--batch-size\", \"4096\", \"--lr\", \"1e-4\",\n    \"--scheduler\", \"cosine\",\n    \"--body-dims\", \"512,256\", \"--dropout\", \"0.1\",\n]\n\nexperiments = [\n    # 23a: asymmetric loss only (3x weight on losses)\n    (\"datasets/az_exp23a_asym.pt\", [\"--loss-asymmetry\", \"2.0\"]),\n    # 23b: negative oversampling only (60% losing positions per batch)\n    (\"datasets/az_exp23b_negsamp.pt\", [\"--negative-oversample\", \"0.6\"]),\n    # 23c: both combined\n    (\"datasets/az_exp23c_both.pt\", [\"--loss-asymmetry\", \"2.0\", \"--negative-oversample\", \"0.6\"]),\n]\n\nfor name, flags in experiments:\n    print(f\"\\n{'='*60}\")\n    print(f\"Training: {name} ({' '.join(flags)})\")\n    print(f\"{'='*60}\\n\")\n    cmd = COMMON + [\"--output\", name] + flags\n    ret = subprocess.run(cmd)\n    if ret.returncode != 0:\n        print(f\"FAILED: {name}\")\n        break\n\nprint(\"\\nDone! Results:\")\n!ls -lh datasets/az_exp23*.pt 2>/dev/null || echo \"No checkpoints found\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy trained models back to Google Drive for download\nimport shutil, os\n\nmodels = [\n    'datasets/az_exp23a_asym.pt',\n    'datasets/az_exp23b_negsamp.pt',\n    'datasets/az_exp23c_both.pt',\n]\n\nfor src in models:\n    name = os.path.basename(src)\n    dst = f'/content/drive/MyDrive/{name}'\n    if os.path.exists(src):\n        shutil.copy2(src, dst)\n        size_mb = os.path.getsize(src) / 1e6\n        print(f\"Saved {dst} ({size_mb:.1f} MB)\")\n    else:\n        print(f\"MISSING: {src}\")\n\nprint(\"\\nDownload from Google Drive, place in local datasets/ folder, then benchmark:\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_exp23a_asym.pt 100 6 400\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_exp23b_negsamp.pt 100 6 400\")\nprint(\"  python /tmp/bench_az_vs_ab.py datasets/az_exp23c_both.pt 100 6 400\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. AlphaZero Self-Play + Training Loop\n\nAutomated generate -> train -> evaluate cycle. Use this for running full\nself-play iterations on Colab hardware."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Full loop: 5 iterations of generate/train/evaluate\n!python -m robottler.az_selfplay loop \\\n    --start-checkpoint robottler/models/az_iter0.pt \\\n    --iterations 5 \\\n    --games-per-iter 200 \\\n    --sims 200 \\\n    --output-dir datasets/az_selfplay/colab_loop \\\n    --epochs 20 \\\n    --eval-games 100 \\\n    --workers {W}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. RL Training (MaskablePPO)\n\nTrain a policy network with reinforcement learning. Benefits from **multi-core** for\nparallel environment rollouts."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m robottler.train_rl \\\n",
    "    --opponent alphabeta \\\n",
    "    --total-steps 200000 \\\n",
    "    --n-envs 8 \\\n",
    "    --bc-model robottler/models/value_net_v2.pt \\\n",
    "    --vps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Save Results\n\nDownload trained models back to your local machine."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all model checkpoints\n",
    "!ls -lh robottler/models/*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip models for download\n",
    "!zip -j colab_models.zip robottler/models/az_colab_*.pt robottler/models/az_iter*.pt 2>/dev/null || echo \"No new models yet\"\n",
    "\n",
    "from google.colab import files\n",
    "try:\n",
    "    files.download(\"colab_models.zip\")\n",
    "except:\n",
    "    print(\"Download manually from the file browser (left panel)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}